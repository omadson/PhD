{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initial clean data of Bicicletar datasets\n",
    "## to-do list\n",
    " - load the datasets\n",
    " - rename column names\n",
    " - combine datetime columns\n",
    " - remove columns with duplication information\n",
    " - remove rows with jornadas < t_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsers for data preprocessing\n",
    "\n",
    "def my_func(row):\n",
    "    mat=re.match('(\\d{2})[/](\\d{2})[/](\\d{4})[ ](\\d{2})[:](\\d{2})[:](\\d{2})$', str(row))\n",
    "    if mat is not None:\n",
    "        return datetime.datetime.strptime(row, \"%d/%m/%Y %H:%M:%S\").strftime('%Y')\n",
    "    else:\n",
    "        return datetime.datetime.strptime(str(row), \"%Y-%m-%d %H:%M:%S\").strftime('%Y')\n",
    "\n",
    "def my_func2(a,b):\n",
    "    b0, b1 = b.split(' ')\n",
    "    horas=int(re.sub(\"\\D\", \"\", b0))\n",
    "    minutos=int(re.sub(\"\\D\", \"\", b1))\n",
    "    return a + datetime.timedelta(minutes=minutos, hours=horas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function to clear the data    \n",
    "def clear_data(year):    \n",
    "    # load the data\n",
    "    brute_path = '../data/bicicletar/'+str(year)+'.xlsx'    \n",
    "    brute_data = pd.read_excel(brute_path)\n",
    "    \n",
    "    if (year != 2017): \n",
    "        # change the columns name\n",
    "        clean_data = brute_data.rename(index=str, columns={'IdJornada': 'id_jornada',\n",
    "                                                           'IdUsuario': 'id_usuario',\n",
    "                                                           'AnoNascimento': 'ano_nascimento',\n",
    "                                                           'Sexo': 'sexo',\n",
    "                                                           'Pais': 'pais',\n",
    "                                                           'Distrito': 'distrito',\n",
    "                                                           'Cidade': 'cidade',\n",
    "                                                           'UF': 'uf',\n",
    "                                                           'DataCadastro': 'data_cadastro',\n",
    "                                                           'Meio de contato para retirada': 'tipo_usuario',\n",
    "                                                           'Bicicleta': 'id_bicicleta',\n",
    "                                                           'DataRetirada': 'data_retirada',\n",
    "                                                           'HoraRetirada': 'hora_retirada',\n",
    "                                                           'DataDevolucao': 'data_devolucao',\n",
    "                                                           'HoraDevolucao': 'hora_devolucao',\n",
    "                                                           'EstacaoRetirada': 'estacao_retirada',\n",
    "                                                           'EstacaoDevolucao': 'estacao_devolucao'});\n",
    "        # set id_jornada to index\n",
    "        clean_data = clean_data.set_index('id_jornada')\n",
    "\n",
    "        # change type of data_cadastro\n",
    "        clean_data['data_cadastro'] = clean_data['data_cadastro'].astype('datetime64')\n",
    "\n",
    "        # combine data_retirada with hora_retirada\n",
    "        clean_data['datetime_retirada'] = clean_data['data_retirada'] + pd.to_timedelta(clean_data['hora_retirada'])\n",
    "        \n",
    "        # combine data_devolucao with hora_devolucao\n",
    "        clean_data['datetime_devolucao'] = clean_data['data_devolucao'] + pd.to_timedelta(clean_data['hora_devolucao'])\n",
    "\n",
    "        # drop columns with duplicate information columns\n",
    "        clean_data = clean_data.drop(['TempoJornada',\n",
    "                                                'TempoJornadaMinutos',\n",
    "                                                'data_retirada',\n",
    "                                                'hora_retirada',\n",
    "                                                'data_devolucao',\n",
    "                                                'hora_devolucao',\n",
    "                                                'distrito'], axis=1)\n",
    "        \n",
    "        if (year == 2016):\n",
    "            dif = clean_data['datetime_devolucao'] - clean_data['datetime_retirada']\n",
    "            idxBugs = dif[(dif<datetime.timedelta(minutes=0))].index\n",
    "            clean_data.loc[idxBugs,['datetime_devolucao']], clean_data.loc[idxBugs,['datetime_retirada']] = \\\n",
    "            clean_data.loc[idxBugs,['datetime_retirada']].values, clean_data.loc[idxBugs,['datetime_devolucao']].values\n",
    "        \n",
    "    else:       \n",
    "        # change the columns name\n",
    "        clean_data = brute_data.rename(index=str, columns={'IdJornada': 'id_jornada',\n",
    "                                                           'globalId': 'id_usuario',\n",
    "                                                           'Sexo': 'sexo',\n",
    "                                                           'País': 'pais',\n",
    "                                                           'Cidade': 'cidade',\n",
    "                                                           'UF': 'uf',\n",
    "                                                           'Data de Cadastro': 'data_cadastro',\n",
    "                                                           'Meio de Retirada': 'tipo_usuario',\n",
    "                                                           'NumExterno': 'id_bicicleta',\n",
    "                                                           'DataCorrida': 'data_corrida',\n",
    "                                                           'HoraRetirada': 'hora_retirada',\n",
    "                                                           'HoraDevolucao': 'hora_devolucao',\n",
    "                                                           'EstacaoRetirada': 'estacao_retirada',\n",
    "                                                           'EstacaoDevolucao': 'estacao_devolucao'});\n",
    "\n",
    "        # set index column\n",
    "        clean_data = clean_data.set_index('id_jornada')\n",
    "\n",
    "        # merge data_corrida with hora_retirada\n",
    "        clean_data['datetime_retirada'] = clean_data['data_corrida'] + pd.to_timedelta(clean_data['hora_retirada'].astype(str))\n",
    "\n",
    "        # merge data_corrida with hora_devolucao\n",
    "        clean_data['datetime_devolucao'] = clean_data.apply(lambda row: my_func2(row['datetime_retirada'],row['Duração da Corrida']), axis=1)\n",
    "        \n",
    "        # fix wrong date inputs\n",
    "        brute_data['ano_nascimento'] = brute_data.apply(lambda row: my_func(row['Nascimento']), axis=1)\n",
    "        brute_data['ano_nascimento'].astype('int')\n",
    "        \n",
    "        #clean_data['datetime_devolucao'] = clean_data['data_corrida'] + pd.to_timedelta(clean_data['hora_devolucao'].astype(str))\n",
    "\n",
    "        # drop columns with duplicate information columns\n",
    "        clean_data = clean_data.drop(['Nascimento',\n",
    "                                      'Projeto',\n",
    "                                      'DiaSemana',\n",
    "                                      'AreaEstacaoRetirada',\n",
    "                                      'EnderecoEstacaoRetirada',\n",
    "                                      'AreaEstacaoDevolucao',\n",
    "                                      'EnderecoEstacaoDevolucao',\n",
    "                                      'Duração da Corrida',\n",
    "                                      'data_corrida',\n",
    "                                      'hora_retirada',\n",
    "                                      'hora_devolucao'], axis=1)\n",
    "    filename = 'clean_data_' + str(year) + '.pkl'\n",
    "    clean_data.index.names = ['id_ano']\n",
    "    clean_data.to_pickle('../data/bicicletar/'+filename)\n",
    "    print('## file \\''+filename+'\\' created.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## file 'clean_data_2015.pkl' created.\n",
      "## file 'clean_data_2016.pkl' created.\n",
      "## file 'clean_data_2017.pkl' created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\renan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "clear_data(2015)\n",
    "clear_data(2016)\n",
    "clear_data(2017)\n",
    "\n",
    "datapath = '../data/bicicletar/clean_data_'\n",
    "data2015 = pd.read_pickle(datapath+'2015.pkl')\n",
    "data2016 = pd.read_pickle(datapath+'2016.pkl')\n",
    "data2017 = pd.read_pickle(datapath+'2017.pkl')\n",
    "\n",
    "all_data = pd.concat([data2015,data2016,data2017])\n",
    "all_data.index.names = ['id_geral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015: 0\n",
      "2016: 0\n",
      "2017: 0\n"
     ]
    }
   ],
   "source": [
    "#Verificar Bug nas datas\n",
    "\n",
    "dif = data2015['datetime_devolucao'] - data2015['datetime_retirada']\n",
    "idxBugs = dif[(dif<datetime.timedelta(minutes=0))].index\n",
    "idxBugs.shape\n",
    "print('2015:',idxBugs.shape[0])\n",
    "\n",
    "dif = data2016['datetime_devolucao'] - data2016['datetime_retirada']\n",
    "idxBugs = dif[(dif<datetime.timedelta(minutes=0))].index\n",
    "idxBugs.shape\n",
    "print('2016:',idxBugs.shape[0])\n",
    "\n",
    "dif = data2017['datetime_devolucao'] - data2017['datetime_retirada']\n",
    "idxBugs = dif[(dif<datetime.timedelta(minutes=0))].index\n",
    "idxBugs.shape\n",
    "print('2017:',idxBugs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_usuario                        1683482\n",
       "sexo                                    M\n",
       "pais                                   BR\n",
       "cidade                          Fortaleza\n",
       "uf                                     CE\n",
       "data_cadastro         27/12/2014 16:55:59\n",
       "estacao_retirada        25 - Torres Câmar\n",
       "tipo_usuario           Cartão Transportes\n",
       "estacao_devolucao       63 - Júlio Azeved\n",
       "id_bicicleta                        15979\n",
       "datetime_retirada     2017-01-01 17:47:06\n",
       "datetime_devolucao    2017-01-02 08:16:06\n",
       "Name: 3283998, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2017.loc[3283998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "~> A função 'dataInfo' levanta algumas informações:\n",
    "  ::Outliers\n",
    "     1. Qual menor tempo de uma viagem entre 2 estações diferentes?\n",
    "     2. Menor e maior tempo de viagem?\n",
    "     3. \n",
    "  \n",
    "  ::Minibicicletar\n",
    "     1. Quantas viagens?\n",
    "     2. Idade desses usuários\n",
    "\n",
    "'''\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta\n",
    "\n",
    "def dataInfo(data):\n",
    "    #calcula diferenca de tempo de devoluçao e retirada\n",
    "    datasRet = pd.to_datetime(data['datetime_retirada'])\n",
    "    datasDev = pd.to_datetime(data['datetime_devolucao'])\n",
    "    dif = datasDev - datasRet       \n",
    "    \n",
    "    # Seleciona viagens com Estação Final é diferente da Estação Inicial\n",
    "    difStations = data[data['estacao_retirada'] != data['estacao_devolucao']]\n",
    "    DS_datasRet = pd.to_datetime(difStations['datetime_retirada'])\n",
    "    DS_datasDev = pd.to_datetime(difStations['datetime_devolucao'])\n",
    "    \n",
    "    #print(difStations)\n",
    "    DS_dif = DS_datasDev - DS_datasRet    \n",
    "    return data[dif<timedelta(minutes=0)][['datetime_retirada','datetime_devolucao','id_ano']], dif\n",
    "#     print(dif<timedelta(minutes=0))\n",
    "#     return dif\n",
    "#     DS_dif[DS_dif>timedelta(minutes=0)]\n",
    "#     print(DS_dif[DS_dif>timedelta(days=1)].shape[0])\n",
    "    \n",
    "    \n",
    "    #print(difStations.loc[(DS_dif>0)])\n",
    "                       \n",
    "    #print(DS_dif.min(),DS_dif.max()) \n",
    "    #print(DS_dif.sort_values(ascending=True))\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this function excludes a few rides based on the following criteria:\n",
    "   1. Starts and finish on the same station;\n",
    "   2. Its total time is less than < t; t is to be defined.\n",
    "'''\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "def remove_rides(data,printReport):\n",
    "    datasRet = pd.to_datetime(data['datetime_retirada'])\n",
    "    datasDev = pd.to_datetime(data['datetime_devolucao'])\n",
    "    dif = datasDev - datasRet\n",
    "    t = [2,3,5,7,9]    \n",
    "    for i in t:\n",
    "        min = timedelta(minutes=i)         \n",
    "        selectedData = data.loc[(dif>=min)]\n",
    "        removedData = data.loc[(dif<min)]\n",
    "        selectedData2 = removedData[removedData['estacao_retirada'] != removedData['estacao_devolucao']]\n",
    "        \n",
    "        if printReport:\n",
    "            print('Minutos:',i)\n",
    "            print('Viagens com tempo acima do mínimo:',selectedData.shape[0])                \n",
    "            print('Viagens com tempo abaixo do mínimo:',removedData.shape[0])               \n",
    "            print('Viagens Recuperadas',selectedData2.shape[0])        \n",
    "            print('TOTAl:',(selectedData.shape[0]+selectedData2.shape[0]))        \n",
    "\n",
    "    print('########################################################')\n",
    "    print(\"Threshold selecionado: 3 minutos;\") \n",
    "    \n",
    "    min = timedelta(minutes=3)         \n",
    "    selectedData = data.loc[(dif>=min)]        \n",
    "    removedData = data.loc[(dif<min)]\n",
    "    selectedData2 = removedData[removedData['estacao_retirada'] != removedData['estacao_devolucao']]\n",
    "    finalCleanData = pd.concat([selectedData,selectedData2])\n",
    "        \n",
    "    print('TOTAl de viagens selecionadas: %d de %d (%.2f%%)' %(finalCleanData.shape[0],data.shape[0],(finalCleanData.shape[0]/data.shape[0])*100))    \n",
    "    return selectedData\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################\n",
      "Threshold selecionado: 3 minutos;\n",
      "TOTAl de viagens selecionadas: 1643774 de 1643774 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "all_data = remove_rides(all_data,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_pickle('TrajetosBicicletar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribuição por Ano de nascimento: ')\n",
    "perYear = all_data.groupby(by='ano_nascimento', as_index=True).agg({'id_usuario': pd.Series.nunique})\n",
    "perYear.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = all_data.id_usuario.unique()\n",
    "print('Total de usuários únicos: ',len(uniques))\n",
    "print('Distribuição por sexo: ')\n",
    "perSex = all_data.groupby(by='sexo', as_index=True).agg({'id_usuario': pd.Series.nunique})\n",
    "perSex.plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Distribuição num de viagens')\n",
    "ridePerId = all_data.groupby(by='id_usuario', as_index=True).agg({'id_jornada': pd.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratar dados 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#data2017.loc[idxBugs]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#new_dif = data2016['datetime_devolucao'] - data2016['datetime_retirada']\n",
    "#new_idxBugs = dif[(dif<timedelta(minutes=0))].index\n",
    "#new_idxBugs.shape\n",
    "#data2016.loc[idxBugs]\n",
    "#data_ = clean_data[dif<timedelta(minutes=0)][['datetime_retirada','datetime_devolucao','id_ano']]  \n",
    "#idxBugs = clean_data.assign(dif=dif[dif<timedelta(minutes=0)]).sort_values(by='id_jornada').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# merge data_corrida with hora_devolucao\\nclean_data['datetime_devolucao'] = clean_data.apply(lambda row: my_func2(row['datetime_retirada'],row['Duração da Corrida']), axis=1)\\n\\n# fix wrong date inputs\\nbrute_data['ano_nascimento'] = brute_data.apply(lambda row: my_func(row['Nascimento']), axis=1)\\nbrute_data['ano_nascimento'].astype('int')\\n\\nclean_data['datetime_devolucao'] = clean_data['data_corrida'] + pd.to_timedelta(clean_data['hora_devolucao'].astype(str))\\n\\n# drop columns with duplicate information columns\\nclean_data = clean_data.drop(['Nascimento',\\n                              'Projeto',\\n                              'DiaSemana',\\n                              'AreaEstacaoRetirada',\\n                              'EnderecoEstacaoRetirada',\\n                              'AreaEstacaoDevolucao',\\n                              'EnderecoEstacaoDevolucao',\\n                              'Duração da Corrida',\\n                              'data_corrida',\\n                              'hora_retirada',\\n                              'hora_devolucao'], axis=1)\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_path = '../data/bicicletar/2017.xlsx'    \n",
    "brute_data = pd.read_excel(brute_path)\n",
    "\n",
    "\n",
    "\n",
    "# change the columns name\n",
    "clean_data = brute_data.rename(index=str, columns={'IdJornada': 'id_jornada',\n",
    "                                                       'globalId': 'id_usuario',\n",
    "                                                       'Sexo': 'sexo',\n",
    "                                                       'País': 'pais',\n",
    "                                                       'Cidade': 'cidade',\n",
    "                                                       'UF': 'uf',\n",
    "                                                       'Data de Cadastro': 'data_cadastro',\n",
    "                                                       'Meio de Retirada': 'tipo_usuario',\n",
    "                                                       'NumExterno': 'id_bicicleta',\n",
    "                                                       'DataCorrida': 'data_corrida',\n",
    "                                                       'HoraRetirada': 'hora_retirada',\n",
    "                                                       'HoraDevolucao': 'hora_devolucao',\n",
    "                                                       'EstacaoRetirada': 'estacao_retirada',\n",
    "                                                       'EstacaoDevolucao': 'estacao_devolucao'});\n",
    "\n",
    "    # set index column\n",
    "clean_data = clean_data.set_index('id_jornada')\n",
    "\n",
    "# merge data_corrida with hora_retirada\n",
    "clean_data['datetime_retirada'] = clean_data['data_corrida'] + pd.to_timedelta(clean_data['hora_retirada'].astype(str))\n",
    "'''\n",
    "# merge data_corrida with hora_devolucao\n",
    "clean_data['datetime_devolucao'] = clean_data.apply(lambda row: my_func2(row['datetime_retirada'],row['Duração da Corrida']), axis=1)\n",
    "\n",
    "# fix wrong date inputs\n",
    "brute_data['ano_nascimento'] = brute_data.apply(lambda row: my_func(row['Nascimento']), axis=1)\n",
    "brute_data['ano_nascimento'].astype('int')\n",
    "\n",
    "clean_data['datetime_devolucao'] = clean_data['data_corrida'] + pd.to_timedelta(clean_data['hora_devolucao'].astype(str))\n",
    "\n",
    "# drop columns with duplicate information columns\n",
    "clean_data = clean_data.drop(['Nascimento',\n",
    "                              'Projeto',\n",
    "                              'DiaSemana',\n",
    "                              'AreaEstacaoRetirada',\n",
    "                              'EnderecoEstacaoRetirada',\n",
    "                              'AreaEstacaoDevolucao',\n",
    "                              'EnderecoEstacaoDevolucao',\n",
    "                              'Duração da Corrida',\n",
    "                              'data_corrida',\n",
    "                              'hora_retirada',\n",
    "                              'hora_devolucao'], axis=1)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_usuario                           int64\n",
       "sexo                                object\n",
       "Nascimento                          object\n",
       "pais                                object\n",
       "cidade                              object\n",
       "uf                                  object\n",
       "data_cadastro                       object\n",
       "Projeto                             object\n",
       "data_corrida                datetime64[ns]\n",
       "DiaSemana                           object\n",
       "hora_retirada                       object\n",
       "estacao_retirada                    object\n",
       "AreaEstacaoRetirada                 object\n",
       "EnderecoEstacaoRetirada             object\n",
       "tipo_usuario                        object\n",
       "hora_devolucao                      object\n",
       "estacao_devolucao                   object\n",
       "AreaEstacaoDevolucao                object\n",
       "EnderecoEstacaoDevolucao            object\n",
       "Duração da Corrida                  object\n",
       "id_bicicleta                         int64\n",
       "datetime_retirada           datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2017-01-02 08:16:06'), Timestamp('2017-01-01 17:47:06'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean_data\n",
    "sample = clean_data.loc[3283998]\n",
    "sample\n",
    "\n",
    "#datetime.fromtimestamp(1172969203.1)\n",
    "#datetime.datetime(2007, 3, 4, 0, 46, 43, 100000)\n",
    "\n",
    "#a = datetime.datetime.fromtimestamp(sample['datetime_retirada'])\n",
    "a = sample['datetime_retirada']\n",
    "b = sample['Duração da Corrida']\n",
    "a,b\n",
    "b0,b1 = b.split(' ')\n",
    "b0,b1\n",
    "horas=int(re.sub(\"\\D\", \"\", b0))\n",
    "minutos=int(re.sub(\"\\D\", \"\", b1))\n",
    "horas,minutos\n",
    "(a+datetime.timedelta(minutes=minutos, hours=horas)),a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_func2(a,b):a\n",
    "    b0, b1 = b.split(' ')\n",
    "    horas=int(re.sub(\"\\D\", \"\", b0))\n",
    "    minutos=int(re.sub(\"\\D\", \"\", b1))\n",
    "    return a + datetime.timedelta(minutes=minutos, hours=horas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
